package main

import (
	"fmt"
	"math/rand"
	"os"
	"time"

	"github.com/edsrzf/mmap-go"
)

const (
	ChunkSize = 50_000_000 // 5000만개씩 처리
)
// 블룸 필터 구조체
type BloomFilter struct {
	// Bloom Filter 크기
	size uint64
	// Bloom Filter 배열
	bf []uint64
	// 해시 함수 개수
	hashFunctions uint64
}

// 사용자 집합 구조체
type UserSet struct {
	// 집합 크기
	size uint16
	// 집합 원소
	elements []uint64
}

// 점진적 유니온 파인드 프로세서
type IncrementalUnionFindProcessor struct {
	dataDir string // 데이터 디렉토리

	// 파일 핸들러
	parentFile *os.File
	rankFile   *os.File
	sizeFile   *os.File

	// mmap 영역 (영구적인 데이터)
	parentArchive mmap.MMap
	rankArchive   mmap.MMap
	sizeArchive   mmap.MMap
	// 현재 윈도우 데이터
	parentSlice []uint64
	rankSlice   []uint8
	sizeSlice   []uint16
	// 윈도우 정보
	windowStart uint64
	windowEnd   uint64
	// 블룸 필터
	//오탐률 0.5%정도, 해시함수 8개.
	totalBloomFilter *BloomFilter // 전체 원소
	multiBloomFilter *BloomFilter // 다중 원소 집합

	// 총 원소 수 및 파일 용량
	totalElements uint64
	fileCapacity  uint64
}

*참고사항 시작*
1. mmap시 해당 알고리즘은 기본적으로 다량의 임의접근을 필연적으로 하게 됨.
2. 다만 그걸 줄이려고 큰 단위 청크로 읽어오게 하는 것. 이걸 최적화하는 설정 등 있으면 해줘.
3. 또한, 초기 파일의 크기는 40억개의 엔트리가 들어온다 가정하고 작성하면 될듯. 
4. 하지만 그렇기 때문에, 청크 단위로 파일을 순회하다가, 특히 parent나 rank,size에서 "null값"(0 등)이 나오면 즉시 순회를 중단하게 하기.
(초기 파일 크기는 크지만, n억개씩 쌓이면서 커지는 거라서, 초기에 채워지지 않는 부분이 생길 수 있음. 이는 굳이 탐색 안하기)
*참고사항 끝*

func (i *IncrementalUnionFindProcessor) ProcessSets(userSets []UserSet) (error, []UserSet) {
	1. 해당 함수는, 집합의 리스트를 받아서, IncrementalUnionFindProcessor의 아카이브를 업데이트 한다.
	1. mulitSets이란 값에 i.ProccesSingleSets(userSets)를 대입한다.
	2. ProcessMultiSets(multiSets)을 호출한다.
}
func (i *IncrementalUnionFindProcessor) ProcessSingleSets(userSets []UserSet) (error, []UserSet) {
	1. 해당 함수는 단일 셋을 골라서 그것을 통해 ncrementalUnionFindProcessor의 아카이브를 업데이트 한다.
	1. multiSets, batchBuffer를 초기화한다.
	2. userSets를 순회한다.
	3. 만약 userSets의 userSet의 size가 2 이상이면 이를 multiSets에 어펜드한다.
	4. 만약 UserSets의의 userSet의 size가 1이면 ReflectSingleSet(userSet, batchBuffer)를 호출한다.i
	5. 순회를 끝낸다.
	6. batchBuffer를 순회하며, 다음 과정을 거친다.
	6-1 : i의 totalBloomfilter에서 batchBuffer값이 있는지 확인한다.
	6-2: 토탈 블룸필터가 있다고 나오면 우선 그 값을 "needToCheck"에 추가하며, 없다고 나오면 "needToBatch"에 추가한다. 
	6-3: "needToCheck"어레이에서, uint64값을 ChunkSize 단위 청크로 잘라서(0~49_999_999사이의 값을 한 청크로 하기), ChunkSize 단위로 슬라이스해온 parentSlice값과 비교하여, 그 값이 이미 존재하는지 확인하다.
	6-3: 이는, parentArchive를 다 로드할 수 없으므로, ChunkSize 슬라이스 청크를 가져와서 확인하기 위함이다.
	6-3: 만약 진짜로 있다고 판명된 경우 스킵하고,실제론 없다고 판명된 경우 이는 needToBatch에 추가한다. 
	6-4: needToBatch어레이 역시, 그 값을 ChunkSize 단위 청크로 잘라서 순회한다. 각 요소는 ChunkSize짜리 parentSlice청크에 자기자신을 루트로 등록한다. 랭크 등도 같이 0으로 초기화한다다. 즉, 유니언파인드의 셋을 자기자신 셋으로 초기화하는 것이다.
	6-4: 이러한 배칭(ChunkSize개의 청크 기반)연산은 BatchSingleSet을 통해 수행한다.
	6-4: 이러한 배칭을 통해 페이지폴트를 ChunkSize번 마다 한번씩 일어나도록 줄일 수 있다.
	7. multeSets를 리턴한다. 
	7. 즉, 해당 함수를 통해 "단일 크기 집합"에 대한 처리를 완료한 후, 복합 크기 집합을 리턴하는 것이다.

}
func (i *IncrementalUnionFindProcessor) BatchSingleSet(batchBuffer []uint64) error {
	1. 해당 함수는 단일 크기 집합을 청크 단위로 IncrementalUnionFindProcessor의 아카이브에 업데이트한다.
	1. batchBuffer를 순회하면서 각 값을 totalBloomFilter에 추가한다.
	2: parsedByChunk 딕셔너리를 생성 후 ParseByChunk(batchBuffer)를 대입한다.
	3: 이후 parsedByChunk 딕셔너리를 순회하며 알맞은 슬라이스를 호출하여 parentSlice를 통해 parentArhive를업데이트 한다.
}

func ParseByChunck (elements []uint64) map[int][]uint64 {
	1. 해당 함수는, uint64배열을 받아서, 그 값을 ChunkSize을 기준으로 청킹한다.
	2. parsedByChunk맵을 초기화
	3. elements를 순회한다.
	4. 0~49_999_999사이의 값은 parsedByChunk[0]에 어펜드, 50_000_000~100_000_000 사이의 앖은 parsedByChunk[1]에 어펜드 하는으로 맵을 업데이트
	5. parsedBychunk를 리턴한다. 
}

func (i *IncrementalUnionFindProcessor) ProcessMultiSets(userSets []UserSet) (error) {
	1. 해당 함수는 크기가 2이상은 집합들을 IncrementalUnionFindProcessor의 아카이브에 반영한다.
	1. 우선 메모리 내에서, DisjointSet구조체를 이용해서 빠르게 [userSet]들 간의 유니언 파인드를 처리한 후. (즉, userSet간의 집합 수를 일단 최대한 줄이고 시작하는 것)
	1-1. disjointSets를 구해낸다. (내부의 정렬 등 아무 상관없고, 단지 disjoint한 리스트의 리스트만 만든다. 즉, disjointSet은 리스트이다.)
	2. 이때, 임시로 type SetWithAnchor struct {anchorToRoot map[uint64]uint64, set *disjointSet변수}를 만든다.
	2-1. 여기서 anchor는 disjointSets의 원소들 중, "아카이브의 복합 셋"에도 그 값이 있는 원소를 의미한다.
	2-1. 즉, 우선은 여기세 i.mutilBloomFilter를 적용시켜 한번 검사 후, 있다는 결과가 나오면 우선은 이들을 maybeAnchor리스트에 추가한다 (오탐 가능성존재).
	2-1. maybeAnchor리스트의 값을 받아낸 뒤 ParseByCHunk(maybeAncor)에 넣어서 maybeAncorByChunk를 만든다. 
	3. maybeAnchorByChunk 순회하며, chunkSize단위로 아카이브의 parentSlice값 받아와서 진짜로 있는지 검사한다. 
	3-1. 만약 유효한 부모를 받을 경우, 그걸 바탕으로 루트 값까지 구해온 후, anchorToRoot의 값에 앵커,루트를 저장한다.
	3-1. 이를 통해 SetWithAnchor를 완성한다.
	4. SetWithAnchor를 순회하며, 그 값들을 받아서,
	4-1. 만약 anchorToRoot가 없다면, 이는 새로운 집합이므로, 일단 이들 유니언을 자체적으로 만들어 newUnionBatch에 만들어 기록해 둔다.
	4-2. 만약 anchorToRoot가 하나 뿐이라면, 이들 유니언을 루트 중심으로 유니언하여 "즉시"아카이브에 기록한다.
	4-2. 이는 GrowMultiset이용한다.
	4-3. 만약 anchorToRoot가 여럿이라면, transitiveClosure를 이용해 루트간의 from-to병합 관계를 미리 연산한다. 이는 rankSlice를 이용한다.
	4-3. 즉,rank를 기반으로 from-to병합을 우선 기록만 하고, 루트 순회 끝난 후 이 기록 바탕으로 finalTo, rank,size등 구해서 그거 바탕으로 유니언 계산 후 "즉시"아카이브에 기록한다.
	4-3. 이는 MergeMultiSet을 이용한다.
	4-4. finally하게 모든 경우에 대해, 각 요소를 i의 totalBloomFilter,muiltBloomfilter에 추가한다.
	5. newUnitonBatch역시 ChunkSize단위로 요소들을 분리 후, 파일에 접근하여 유니언 배치를 한번에 업데이트 한다.
	5. 이는 BatchAddMultiSet을 이용한다.



}

func (i *IncrementalUnionFindProcessor) BatchAddMultiSet(userSets []UserSet) error {
	1. 해당 함수는 []userSet을 순회하면서 첫 원소를 루트로 여기고, 이들 연산을 청크 단위로 업데이트 한다.
	1. map[int]->[2][uint64]를 만든다.
	2. 이는, int번쨰의 청크에 접근해서, [0]은 인덱스, [1]은 삽입할 루트 값을 저장한다.
	2. 예컨데, userSets의 userSet이 [1,2,3]이라면, 이들 값은 전부 0번 청크이고, 1을 루트로 하는 [0]->[1][1 or 2 or 3]인 것 
	3. 이런 식으로 일단 이 map을 전부 기록한다.
	4. 이를 기록 한 후 청크를 순회하며 배칭 형태로 업데이트 한다.
	5. rank, size도 업뎃.

}
func (i *IncrementalUnionFindProcessor) GrowMultiSet(userSet UserSet) error {
	1. 해당 함수는 다른 집합과 머지할 필요 없는, 닫힌 집합을 IncrementalUnionFindProcessor의 아카이브에 반영한다.
    1. userSet.elements 중 첫 원소를 루트원소로 잡아서 유니언한다.
	2. parentMap, rankMap을 만들어 element와 그 유니언, 랭크를 저장한다
	2. parsedByChunk 딕셔너리를 만들어 ParseByChunck(userSet.elements)를 대입한다.
	3. 해당 parseByChunk를 순회하며, parenMap,rankMap을 참고하여, ChunkSize 단위로 받아온 슬라이스에 정보를 추가한다. 


}
func (i *IncrementalUnionFindProcessor) MergeMultiSet(userSet UserSet) error {
	1. 여러 앵커가 존재하는 상황에서, 아카이브의 여러 트리를 병합하는 함수이다.
	2. 즉, 각 트리의 앵커, 루트와, userSet이 존재하는 상황에서
	3. rankData를 기반으로 전이적인 닫힌집합을 생성해서 단 하나의 루트를 구해낸다.
	4. rootUnions := make(map[uint64]uint64) // from -> to
	5. 이런 식으로 설정 후 랭크비교로 from-to연산, 
	6. 이후  for문 돌면서 finalTo :=to에서 시작해서, from->to해도 닫혔을 때 멈춤
	7. 이후, 모든 root와 userSet(여기 앵커도 포함)의 parent를 finalTo로 수정하기를 "기록"한다 (size, rank도 마찬가지)
	8. 이후 이를 다시 청크화해서 청크별로 돌면서 parent, rank, size등을 업데이트 한다.

}


// 받아온 멀티셋들을 임시로 클러스터링해두는 유니언파인드 구조체.
// 메인 로직에는 사용하지 말고, 변수로 받은 muliSet을 임시로 묶을 때 사용하기.
// DisjointSet는 분리 집합을 관리하는 유니온 파인드 구조체입니다.
type DisjointSet struct {
	parent map[uint64]uint64 // 각 원소의 부모를 저장
	rank   map[uint64]int    // 트리의 높이를 저장 (최적화용)
}

// NewDisjointSet은 새로운 DisjointSet 인스턴스를 생성합니다.
func NewDisjointSet() *DisjointSet {
	return &DisjointSet{
		parent: make(map[uint64]uint64),
		rank:   make(map[uint64]int),
	}
}

// MakeSet은 새로운 원소를 집합에 추가합니다.
func (ds *DisjointSet) MakeSet(x uint64) {
	if _, exists := ds.parent[x]; exists {
		return // 이미 존재하는 원소는 무시
	}

	ds.parent[x] = x // 자기 자신을 부모로 설정
	ds.rank[x] = 0   // 초기 랭크는 0
}

// Find는 원소 x가 속한 집합의 대표(루트)를 찾습니다.
// 경로 압축 최적화를 적용합니다.
func (ds *DisjointSet) Find(x uint64) uint64 {
	if _, exists := ds.parent[x]; !exists {
		ds.MakeSet(x)
	}

	if ds.parent[x] != x {
		ds.parent[x] = ds.Find(ds.parent[x]) // 경로 압축
	}
	return ds.parent[x]
}

// Union은 두 원소가 속한 집합을 합칩니다.
// 랭크에 따른 병합 최적화를 적용합니다.
func (ds *DisjointSet) Union(x, y uint64) {
	rootX := ds.Find(x)
	rootY := ds.Find(y)

	if rootX == rootY {
		return // 이미 같은 집합에 속해 있음
	}

	// 랭크에 따라 병합 (랭크가 작은 트리를 랭크가 큰 트리에 붙임)
	if ds.rank[rootX] < ds.rank[rootY] {
		ds.parent[rootX] = rootY
	} else {
		ds.parent[rootY] = rootX

		// 두 트리의 랭크가 같으면 결과 트리의 랭크를 증가
		if ds.rank[rootX] == ds.rank[rootY] {
			ds.rank[rootX]++
		}
	}
}

// GetSets는 현재 분리된 모든 집합들을 반환합니다.
func (ds *DisjointSet) GetSets() map[uint64][]uint64 {
	result := make(map[uint64][]uint64)

	// 모든 요소를 순회하며 집합을 계산
	for element := range ds.parent {
		root := ds.Find(element) // 경로 압축이 여기서도 발생

		if _, exists := result[root]; !exists {
			result[root] = []uint64{}
		}
		result[root] = append(result[root], element)
	}


	return result
}

// PrintSets는 현재 모든 분리 집합과 그 원소들을 출력합니다.
func (ds *DisjointSet) PrintSets() {
	sets := ds.GetSets()

	fmt.Println("현재 분리 집합 상태:")

	for _, set := range sets {
		fmt.Printf("집합의 원소들: %v\n", set)
	}
}



// 더 메모리 효율적인 GenerateSets 함수
func GenerateSets(rangeValue uint64, setSize int, count int) []UserSet {
	result := make([]UserSet, 0, count)

	// 작은 청크로 나누어 진행

	for len(result) < count {
		// 지역 맵을 사용하여 청크마다 메모리 해제
		usedElements := make(map[uint64]bool)
		for i := 0; i < chunkSize && len(result) < count; i++ {
			set := UserSet{Elements: make([]uint64, 0, setSize)}
			// 중복되지 않는 원소를 setSize만큼 추가
			for j := 0; j < setSize; j++ {
				var element uint64
				maxAttempts := 100 // 무한 루프 방지
				attempts := 0

				for attempts < maxAttempts {
					element = uint64(rand.Int63n(int64(rangeValue))) + 1 // 1부터 시작
					if !usedElements[element] {
						break
					}
					attempts++
				}

				// maxAttempts에 도달하면 중복 허용
				set.Elements = append(set.Elements, element)
				usedElements[element] = true
			}

			result = append(result, set)
		}
	}
	runtime.GC()

	return result
}

// 대폭 개선된 GenerateAllSets 함수
func GenerateAllSets(numSets uint64, rangeValue uint64) []UserSet {

	// 분포 계산은 동일하게 유지
	singleCount := int(float64(numSets) * 0.90)   // 90%
	twoCount := int(float64(numSets) * 0.07)      // 7%
	threeCount := int(float64(numSets) * 0.01)    // 1%
	fourCount := int(float64(numSets) * 0.005)    // 0.5%
	fiveCount := int(float64(numSets) * 0.0025)   // 0.25%
	sixCount := int(float64(numSets) * 0.0025)    // 0.25%
	sevenCount := int(float64(numSets) * 0.0025)  // 0.25%
	eightCount := int(float64(numSets) * 0.0025)  // 0.25%
	nineCount := int(float64(numSets) * 0.001)    // 0.1%
	tenCount := int(float64(numSets) * 0.001)     // 0.1%
	elevenCount := int(float64(numSets) * 0.0005) // 0.05%
	twelveCount := int(float64(numSets) * 0.0005) // 0.05%
	twentyCount := int(float64(numSets) * 0.0003) // 0.03%
	thirtyCount := int(float64(numSets) * 0.0001) // 0.01%
	fiftyCount := int(float64(numSets) * 0.0001)  // 0.01%

	// 결과 슬라이스
	allSets := make([]UserSet, 0, numSets)

	// 각 크기별 집합 생성
	fmt.Println("1개 원소 집합 생성 중...")
	allSets = append(allSets, GenerateSets(rangeValue, 1, singleCount)...)
	fmt.Println("2개 원소 집합 생성 중...")
	allSets = append(allSets, GenerateSets(rangeValue, 2, twoCount)...)
	fmt.Println("3개 원소 집합 생성 중...")
	allSets = append(allSets, GenerateSets(rangeValue, 3, threeCount)...)
	fmt.Println("4-12개 원소 집합 생성 중...")
	allSets = append(allSets, GenerateSets(rangeValue, 4, fourCount)...)
	allSets = append(allSets, GenerateSets(rangeValue, 5, fiveCount)...)
	allSets = append(allSets, GenerateSets(rangeValue, 6, sixCount)...)
	allSets = append(allSets, GenerateSets(rangeValue, 7, sevenCount)...)
	allSets = append(allSets, GenerateSets(rangeValue, 8, eightCount)...)
	allSets = append(allSets, GenerateSets(rangeValue, 9, nineCount)...)
	allSets = append(allSets, GenerateSets(rangeValue, 10, tenCount)...)
	allSets = append(allSets, GenerateSets(rangeValue, 11, elevenCount)...)
	allSets = append(allSets, GenerateSets(rangeValue, 12, twelveCount)...)
	fmt.Println("다수 원소 집합 생성 중...")
	allSets = append(allSets, GenerateSets(rangeValue, 20, twentyCount)...)
	allSets = append(allSets, GenerateSets(rangeValue, 30, thirtyCount)...)
	allSets = append(allSets, GenerateSets(rangeValue, 50, fiftyCount)...)

	// 랜덤하게 섞기
	fmt.Println("집합 섞는 중...")
	rand.Seed(time.Now().UnixNano())
	rand.Shuffle(len(allSets), func(i, j int) {
		allSets[i], allSets[j] = allSets[j], allSets[i]
	})

	fmt.Printf("총 %d개 집합 생성 완료\n", len(allSets))

	return allSets
}




// 아래의 GenerateAndSaveSets 함수는 plnaB용 함수라, 지금은 사용 ㄴ
//만약 한번에 2억개 집합 컨트롤 못할 경우 파일로 1억개씩 끊어서 two-phase로 처리하는 경우르 planB로 해둔 것
// // 청크 단위로 집합을 생성하고 파일에 저장하는 함수
// func GenerateAndSaveSets(numSets uint64, rangeValue uint64, phase int) (int, error) {
// 	// 청크별로 파일 생성
// 	totalChunks := (numSets + SetChunkSize - 1) / SetChunkSize // 올림 나눗셈
// 	var totalSets int

// 	for chunk := uint64(0); chunk < totalChunks; chunk++ {
// 		// 현재 청크에서 생성할 집합 수 계산
// 		chunkSetCount := SetChunkSize
// 		if (chunk+1)*SetChunkSize > numSets {
// 			chunkSetCount = int(numSets - chunk*SetChunkSize)
// 		}

// 		fmt.Printf("청크 %d/%d: %d개 집합 생성 중...\n", chunk+1, totalChunks, chunkSetCount)

// 		// 결과 슬라이스
// 		chunkSets := make([]UserSet, 0, chunkSetCount)

// 		// 각 크기별 집합 생성
// 		chunkSets = GenerateAllSets(uint64(chunkSetCount), rangeValue)

// 		// 파일에 저장
// 		fileName := fmt.Sprintf("%s_phase%d_chunk_%d.gob", SetFilePath, phase, chunk)
// 		if err := SaveSetsToFile(chunkSets, fileName); err != nil {
// 			return totalSets, err
// 		}

// 		totalSets += len(chunkSets)

// 		// 메모리 정리
// 		chunkSets = nil
// 		runtime.GC()

// 		fmt.Printf("  청크 %d 저장 완료 (%s)\n", chunk+1, fileName)
// 	}

// 	return totalSets, nil
// }
